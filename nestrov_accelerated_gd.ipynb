{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LN Pandey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import openpyxl\n",
    "'''train = np.array([\n",
    "    [0,0,1,2,3],\n",
    "    [1,1,2,3,4],\n",
    "    [2,2,3,4,5],\n",
    "    [3,3,4,5,6]\n",
    "]\n",
    ")'''\n",
    "'''\n",
    "train = np.array([\n",
    "    [0,1,1,1,3],\n",
    "    [1,1,1,1,4],\n",
    "    [2,1,1,1,5],\n",
    "    [3,1,1,1,6]\n",
    "]\n",
    ")'''\n",
    "train = pd.read_csv('train.csv').as_matrix()#read train.csv file\n",
    "#print(type(train))\n",
    "#xtrain=train[:,1:4]\n",
    "#xtrain = xtrain/5\n",
    "#true_label=train[:,4:5]\n",
    "#print((xtrain),(true_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_into_prob(x,max_val):\n",
    "    len=x.size\n",
    "    y_list=[]\n",
    "    for i in range(len):\n",
    "        temp=[]\n",
    "        for j in range(max_val):\n",
    "            if(x[i]==j):\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "            #print(temp)\n",
    "        y_list.append(temp)\n",
    "    return y_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.55945675 -0.55945675  2.06254185 ...  2.0522595  -0.55945675\n",
      "  -0.55945675]\n",
      " [-0.5380259  -0.5380259  -0.5380259  ... -0.5380259  -0.5380259\n",
      "  -0.5380259 ]\n",
      " [-0.6486501  -0.6486501  -0.6486501  ... -0.6486501  -0.6486501\n",
      "  -0.6486501 ]\n",
      " ...\n",
      " [-0.64973918 -0.64973918 -0.64973918 ... -0.64973918 -0.64973918\n",
      "  -0.64973918]\n",
      " [-0.59745866 -0.59745866 -0.59745866 ... -0.59745866 -0.59745866\n",
      "  -0.59745866]\n",
      " [-0.62629522 -0.62629522 -0.62629522 ... -0.62629522 -0.62629522\n",
      "  -0.62629522]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "xtrain=train[:,1:785]\n",
    "\n",
    "xmean = np.mean(xtrain , axis=1)\n",
    "means_expanded = np.outer(xmean, np.ones(784))\n",
    "#print(means_expanded)\n",
    "xtrain = xtrain - means_expanded\n",
    "\n",
    "xstd = np.std(xtrain , axis=1)\n",
    "std_expanded = np.outer(xstd, np.ones(784))\n",
    "#print(std_expanded)\n",
    "xtrain = xtrain*1.0/std_expanded \n",
    "\n",
    "true_label = train[:,785:]\n",
    "y_true=np.array(encode_into_prob(true_label,10))\n",
    "y_true=y_true.transpose()\n",
    "\n",
    "#print(type(y_true))\n",
    "#print(y_true.transpose())\n",
    "print(xtrain)\n",
    "print((y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(batch_train,hidden_layers):\n",
    "     \n",
    "    global weight_matrix_list\n",
    "    global bias_list\n",
    "    global preactivation_list \n",
    "    preactivation_list=[]\n",
    "    global activation_list\n",
    "    activation_list=[]\n",
    "    global y_hat\n",
    "    y_hat=[]\n",
    "    a_new=[]\n",
    "    a_last_layer=[]\n",
    "    nos_data = len(batch_train)\n",
    "    #print(nos_data)\n",
    "    h=batch_train.transpose()\n",
    "    preactivation_list.append(h)\n",
    "    activation_list.append(h)\n",
    "    #print(h)\n",
    "    \n",
    "#     print(\"y_hat in feed\\n\",y_hat )\n",
    "    \n",
    "    for j in range(hidden_layers):\n",
    "        \n",
    "#         print(\".............................\")\n",
    "#         print(\"activation for layer \", j)\n",
    "#         print(activation_list[j] , activation_list[j].shape)\n",
    "#         print(\"weight\",j+1)\n",
    "#         print(weight_matrix_list[j], weight_matrix_list[j].shape)\n",
    "#         print(\"bias \",j+1)\n",
    "#         print(bias_list[j],bias_list[j].shape)\n",
    "        \n",
    "        a_new = bias_list[j]+np.matmul(weight_matrix_list[j].transpose(),activation_list[j])\n",
    "        preactivation_list.append(a_new)\n",
    "        \n",
    "#         print(\"preactivation for layer\",j+1)\n",
    "#         print(preactivation_list[j+1], preactivation_list[j+1].shape)\n",
    "        \n",
    "        h = 1.0/(1.0+np.exp(-1*preactivation_list[j+1]))\n",
    "        activation_list.append(h)\n",
    "\n",
    "    \n",
    "    j=hidden_layers\n",
    "#     print(\".............................\")\n",
    "#     print(\"activation for layer \", j)\n",
    "#     print(activation_list[j] , activation_list[j].shape)\n",
    "#     print(\"weight\",j+1)\n",
    "#     print(weight_matrix_list[j], weight_matrix_list[j].shape)\n",
    "#     print(\"bias \",j+1)\n",
    "#     print(bias_list[j],bias_list[j].shape)\n",
    "    \n",
    "    a_last_layer = bias_list[j]+np.matmul(weight_matrix_list[j].transpose(),activation_list[j])\n",
    "    preactivation_list.append(a_last_layer)\n",
    "    \n",
    "#     print(\"last activation\")\n",
    "#     print(a_last_layer,a_last_layer.shape)\n",
    "\n",
    "    y_hat = np.array(output(a_last_layer,batch_train))\n",
    "    y_hat = y_hat.transpose()\n",
    "    \n",
    "#     print(\"y_hat in feedforward\")\n",
    "#     print(y_hat, y_hat.shape)\n",
    "    \n",
    "    \n",
    "def output(a_last_layer,batch_train):\n",
    "    y_hat_initial=[]\n",
    "    y_hat_local=[]\n",
    "    nos_data=len(batch_train)\n",
    "    for i in range(nos_data):\n",
    "        y_hat_initial.append(softmax(a_last_layer[:,i:i+1].transpose()))\n",
    "\n",
    "    length = len(y_hat_initial)\n",
    "    for i in range(length):\n",
    "        y_hat_local.append(y_hat_initial[i][0])\n",
    "    \n",
    "#     print(\"y_hat_local\", y_hat_local)\n",
    "#     print(\"y_hat_initial\",y_hat_initial)\n",
    "    return y_hat_local\n",
    "\n",
    "def softmax(row_vector):\n",
    "    sum_all=0\n",
    "    row_vector = np.exp(row_vector)\n",
    "    sum_all = np.sum(row_vector , axis=1)         #print(\"row_vector\", row_vector)\n",
    "    row_vector = (row_vector*1.0/sum_all)         #print(\"sum_all\",sum_all)\n",
    "    return row_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(y_true_batch):\n",
    "    \n",
    "#     print(\"weigt in backpropogation\", weight_matrix_list)\n",
    "#     print(\"...........y_true_batch..........\\n\",y_true_batch)\n",
    "    \n",
    "    global grad_a_k_list\n",
    "    grad_a_k_list=[]\n",
    "    \n",
    "    global grad_w_k_list\n",
    "    grad_w_k_list=[]\n",
    "    \n",
    "    global grad_h_k_list\n",
    "    grad_h_k_list=[]\n",
    "    \n",
    "    global grad_b_k_list\n",
    "    grad_b_k_list=[]\n",
    "    \n",
    "    global grad_b\n",
    "    grad_b=[]\n",
    "    \n",
    "    global grad_g_dash_a_k_list\n",
    "    grad_g_dash_a_k_list = []\n",
    "    \n",
    "    global grad_a_last\n",
    "    grad_a_last=[]\n",
    "    \n",
    "    k = num_hidden+1\n",
    "    \n",
    "#     print(\"--------------------------in Backpropagation---------------------\")\n",
    "    \n",
    "    grad_g_dash_a_k_list = g_dash(preactivation_list)\n",
    "    \n",
    "#     print(\"preactivation_list....................\")\n",
    "#     print(\"Nos. of matrices in preactivation_list is\", len(preactivation_list))\n",
    "#     print(preactivation_list)\n",
    "#     print(\"g_dash..................\")\n",
    "#     print(\"Nos. of matrices in g_dash is \", len(grad_g_dash_a_k_list))\n",
    "#     print(grad_g_dash_a_k_list)\n",
    "    \n",
    "    grad_a_last = -np.subtract(y_true_batch,y_hat)\n",
    "    \n",
    "#     print(\"y_true_batch \\n\", y_true_batch)\n",
    "#     print(\"y_hat \\n\",y_hat)\n",
    "    \n",
    "    grad_a_k_list.insert(0,grad_a_last)\n",
    "    \n",
    "#     print(\"grad_a_last_layer\", k)\n",
    "#     print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "        \n",
    "    while(k>0):\n",
    "        \n",
    "#         print(\".................grad_compute at layer\",k)\n",
    "        \n",
    "        grad_w_k_list.insert(0,np.matmul(grad_a_k_list[0],preactivation_list[k-1].transpose()))\n",
    "        \n",
    "#         print(\"grad_a\", k)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "#         print('preactivation  a_',k-1)\n",
    "#         print(preactivation_list[k-1],preactivation_list[k-1].shape)\n",
    "#         print(\"grad_w_\",k)\n",
    "#         print(grad_w_k_list[0],grad_w_k_list[0].shape)\n",
    "        \n",
    "        grad_b_k_list.insert(0,grad_a_k_list[0])\n",
    "        \n",
    "#         print(\"grad_b\",k)\n",
    "#         print(grad_b_k_list[0],grad_b_k_list[0].shape)\n",
    "        \n",
    "        grad_h_k_list.insert(0,np.matmul(grad_w_k_list[0].transpose(),grad_a_k_list[0]))\n",
    "        \n",
    "#         print(\"grad_w\",k)\n",
    "#         print(grad_w_k_list[0],grad_w_k_list[0].shape)\n",
    "#         print(\"grad_a\",k)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "#         print(\"grad_h\",k-1)\n",
    "#         print(grad_h_k_list[0],grad_h_k_list[0].shape)\n",
    "        \n",
    "        grad_a_k_list.insert(0,np.multiply(grad_h_k_list[0],grad_g_dash_a_k_list[k-1]))\n",
    "        \n",
    "#         print(\"grad_h_k_list[0]\",k-1)\n",
    "#         print(grad_h_k_list[0],grad_h_k_list[0].shape)\n",
    "#         print(\"grad_g_dash_a_k_list[k-1]\",k-1)\n",
    "#         print(grad_g_dash_a_k_list[k-1],grad_g_dash_a_k_list[k-1].shape)\n",
    "#         print(\"grad_a\",k-1)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "        k=k-1\n",
    "#         print(\"grad_a_ik_list\",grad_a_k_list[0])\n",
    "    \n",
    "    sum_all_grad_b_of_data(grad_b_k_list)\n",
    "    \n",
    "\n",
    "def sum_all_grad_b_of_data(grad_b_k_list):\n",
    "    length=len(grad_b_k_list)\n",
    "    i=0\n",
    "    while(i<length):\n",
    "        row=[]\n",
    "        row = np.sum(grad_b_k_list[i],1)\n",
    "        j = len(row)\n",
    "        #print(row.shape)\n",
    "        row = row[:, np.newaxis]\n",
    "        #print(row.shape , row)\n",
    "        grad_b.append(row)\n",
    "        i+=1\n",
    "    #print(\"grad_b\",grad_b)\n",
    "\n",
    "def g_dash(preactivation_list):\n",
    "    length=len(preactivation_list)\n",
    "    a_modified = preactivation_list[0:length]\n",
    "    g_dash_a_k_list=[]\n",
    "    for i in range(length):\n",
    "        a=(1.0/(1+np.exp(-a_modified[i])))*(1-(1.0/(1+np.exp(-a_modified[i]))))\n",
    "        g_dash_a_k_list.append(a)\n",
    "    return g_dash_a_k_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_yhat_to_classes(y_hat_local):\n",
    "    col = len(y_hat_local[0])\n",
    "    max_val=0\n",
    "    for j in range(col):\n",
    "        max_val = y_hat_local[0][j]\n",
    "        index=0\n",
    "        for i in range(9):\n",
    "            if(y_hat_local[i+1][j] > max_val):\n",
    "                y_hat_local[index][j]=0\n",
    "                index = i+1\n",
    "                max_val=y_hat[i+1][j]\n",
    "            else :\n",
    "                y_hat_local[i+1][j]=0\n",
    "        y_hat_local[index][j]=1\n",
    "    return y_hat_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 10]\n",
      "2\n",
      "[array([[0.00206275, 0.00359858, 0.00426711, ..., 0.00814957, 0.0043645 ,\n",
      "        0.00522144],\n",
      "       [0.00322303, 0.00379487, 0.00396095, ..., 0.00977087, 0.00795203,\n",
      "        0.00294954],\n",
      "       [0.0037125 , 0.00950683, 0.00829493, ..., 0.00747716, 0.00793004,\n",
      "        0.00971369],\n",
      "       ...,\n",
      "       [0.00657197, 0.00621005, 0.00859556, ..., 0.00785171, 0.00750636,\n",
      "        0.00413116],\n",
      "       [0.00693964, 0.00417373, 0.00139809, ..., 0.00017605, 0.00818562,\n",
      "        0.00525348],\n",
      "       [0.0096623 , 0.00225102, 0.00329946, ..., 0.00168053, 0.00653391,\n",
      "        0.00013677]])]\n",
      "[array([[0.00538525],\n",
      "       [0.0045405 ],\n",
      "       [0.00454688],\n",
      "       [0.00185866],\n",
      "       [0.00171154],\n",
      "       [0.00175973],\n",
      "       [0.00323049],\n",
      "       [0.00306376],\n",
      "       [0.00686285],\n",
      "       [0.00709521]])]\n"
     ]
    }
   ],
   "source": [
    "#ip_neurons = 3 #input layer\n",
    "ip_neurons = 784\n",
    "num_hidden = 0\n",
    "encoding_bits=10\n",
    "sizes = []\n",
    "sizes.insert(0,ip_neurons)\n",
    "sizes.append(encoding_bits)\n",
    "print(sizes)\n",
    "print(len(sizes))\n",
    "\n",
    "weight_matrix_list = []\n",
    "\n",
    "bias_list =[]\n",
    "y_hat= []\n",
    "\n",
    "for i in range(int(num_hidden)+1):\n",
    "    weight_matrix_list.append(0.01*np.random.rand(sizes[i],sizes[i+1]))\n",
    "    bias_list.append(0.01*np.random.rand(sizes[i+1],1))\n",
    "print(weight_matrix_list)\n",
    "#print(len(weight_matrix_list))\n",
    "\n",
    "print(bias_list)\n",
    "#print(hlist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestrov_accelerated_gradient_descent(weight_matrix_list,bias_list,xtrain,num_hidden,sizes):\n",
    "    \n",
    "    prev_v_w = [] \n",
    "    prev_v_b = []\n",
    "    for i in range(int(num_hidden)+1):\n",
    "        prev_v_w.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "        prev_v_b.append(0*np.random.rand(sizes[i+1],1))\n",
    "    \n",
    "    v_w = [] \n",
    "    v_b =[]\n",
    "    for i in range(int(num_hidden)+1):\n",
    "        v_w.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "        v_b.append(0*np.random.rand(sizes[i+1],1))\n",
    "        \n",
    "    len_w = len(weight_matrix_list)  \n",
    "    len_b = len(bias_list)\n",
    "    \n",
    "    eta = 0.001\n",
    "    batch_size = 10\n",
    "    steps = 0\n",
    "    gamma = 0.9\n",
    "    epochs = 10\n",
    "    t=0\n",
    "    data_length = len(xtrain)\n",
    "    no_of_batch = int(data_length/batch_size)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        for batch in range(no_of_batch):\n",
    "            dw=[]\n",
    "            db=[]\n",
    "            for i in range(int(num_hidden)+1):\n",
    "                dw.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "                db.append(0*np.random.rand(sizes[i+1],1))\n",
    "                \n",
    "            for j in range(len_w): \n",
    "                v_w[j] = gamma*prev_v_w[j]\n",
    "                                    \n",
    "            for j in range(len_b):\n",
    "                v_b[j] = gamma*prev_v_b[j]\n",
    "            \n",
    "            for j in range(len_w):\n",
    "                weight_matrix_list[j] -= v_w[j]\n",
    "            \n",
    "            for j in range(len_b):\n",
    "                bias_list[j] -= v_b[j]\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                l = batch_size*batch + i\n",
    "                r = batch_size*batch + i + 1\n",
    "                feedforward(xtrain[l:r,:],num_hidden)\n",
    "                #print(l , r)\n",
    "                backpropagation(y_true[:,l:r])\n",
    "\n",
    "                for j in range(len_w): \n",
    "                    dw[j] += grad_w_k_list[j].transpose()\n",
    "                                    \n",
    "                for j in range(len_b):\n",
    "                    db[j] += grad_b[j]\n",
    "                                \n",
    "            \n",
    "            for j in range(len_w): \n",
    "                v_w[j] = gamma*prev_v_w[j] + eta*dw[j]\n",
    "                                    \n",
    "            for j in range(len_b):\n",
    "                v_b[j] = gamma*prev_v_b[j] + eta*db[j]\n",
    "                \n",
    "            for j in range(len_w):\n",
    "                weight_matrix_list[j] += -1*eta*dw[j]\n",
    "            \n",
    "            for j in range(len_b):\n",
    "                bias_list[j] = -1*eta*db[j]\n",
    "                \n",
    "            for j in range(len_w): \n",
    "                prev_v_w[j] = v_w[j]\n",
    "                                    \n",
    "            for j in range(len_b):\n",
    "                prev_v_b[j] = v_b[j]\n",
    "                \n",
    "            \n",
    "        \n",
    "        print(\"end of epoch\" , t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of epoch 0\n",
      "end of epoch 1\n",
      "end of epoch 2\n",
      "end of epoch 3\n",
      "end of epoch 4\n",
      "end of epoch 5\n",
      "end of epoch 6\n",
      "end of epoch 7\n",
      "end of epoch 8\n",
      "end of epoch 9\n"
     ]
    }
   ],
   "source": [
    "nestrov_accelerated_gradient_descent(weight_matrix_list,bias_list,xtrain,num_hidden,sizes)\n",
    "#print(y_hat)0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.40495942e-15]\n",
      " [2.21294782e-05]\n",
      " [1.86380810e-08]\n",
      " [1.66895552e-09]\n",
      " [2.02656640e-19]\n",
      " [1.18775787e-17]\n",
      " [9.99542288e-01]\n",
      " [2.43635880e-05]\n",
      " [1.29748374e-05]\n",
      " [3.98223983e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LN Pandey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\LN Pandey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def decode_yhat_to_classes(y_hat):\n",
    "    col = len(y_hat[0])\n",
    "    max_val=0\n",
    "    for j in range(col):\n",
    "        max_val = y_hat[0][j]\n",
    "        index=0\n",
    "        for i in range(9):\n",
    "            if(y_hat[i+1][j] > max_val):\n",
    "                y_hat[index][j]=0\n",
    "                index = i+1\n",
    "                max_val=y_hat[i+1][j]\n",
    "            else :\n",
    "                y_hat[i+1][j]=0\n",
    "        y_hat[index][j]=1\n",
    "    return y_hat\n",
    "xtest = pd.read_csv('test.csv').as_matrix()\n",
    "test=xtest[:,1:]\n",
    "feedforward(test,num_hidden)\n",
    "#print(y_hat)\n",
    "y_hat = decode_yhat_to_classes(y_hat)\n",
    "#print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)\n",
    "y_hat = decode_yhat_to_classes(y_hat)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation(y_hat):\n",
    "    y_predict=[]\n",
    "    col = len(y_hat[0])\n",
    "    for j in range(col):\n",
    "        for i in range(10):\n",
    "            if(y_hat[i][j]==1):\n",
    "                y_predict.append(i+1)\n",
    "                break\n",
    "    return np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 ... 4 4 4]\n",
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [4]\n",
      " [4]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifcation(y_hat)\n",
    "print((y_predict))\n",
    "y_predict = y_predict[:, np.newaxis]\n",
    "print((y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_to_y_predict(y_predict):\n",
    "    ide=[]\n",
    "    row=len(y_predict)\n",
    "    for i in range(row):\n",
    "        ide.append(i)\n",
    "    ide=np.array(ide)\n",
    "    ide=ide[:,np.newaxis]\n",
    "    y= np.hstack((ide,y_predict))\n",
    "    #print(y_predict, ide)\n",
    "    return y           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [4]\n",
      " [4]\n",
      " [4]]\n",
      "[[   0    4]\n",
      " [   1    4]\n",
      " [   2    4]\n",
      " ...\n",
      " [9997    4]\n",
      " [9998    4]\n",
      " [9999    4]]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)\n",
    "#y_predict= np.random.randint(10, size=(10000, 1))\n",
    "y_predict= add_id_to_y_predict(y_predict)\n",
    "print(y_predict)\n",
    "x,y = y_predict.shape\n",
    "#print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict.csv', 'w', newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    row,col=y_predict.shape \n",
    "    thewriter.writerow(['id','label'])\n",
    "    for i in range(row):\n",
    "        thewriter.writerow(y_predict[i])\n",
    "#out.close()\n",
    "#np.savetxt(\"foo.csv\", y_predict, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
