{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LN Pandey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import openpyxl\n",
    "'''train = np.array([\n",
    "    [0,0,1,2,3],\n",
    "    [1,1,2,3,4],\n",
    "    [2,2,3,4,5],\n",
    "    [3,3,4,5,6]\n",
    "]\n",
    ")'''\n",
    "'''\n",
    "train = np.array([\n",
    "    [0,1,1,1,3],\n",
    "    [1,1,1,1,4],\n",
    "    [2,1,1,1,5],\n",
    "    [3,1,1,1,6]\n",
    "]\n",
    ")'''\n",
    "train = pd.read_csv('train.csv').as_matrix()#read train.csv file\n",
    "#print(type(train))\n",
    "#xtrain=train[:,1:4]\n",
    "#xtrain = xtrain/5\n",
    "#true_label=train[:,4:5]\n",
    "#print((xtrain),(true_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_into_prob(x,max_val):\n",
    "    len=x.size\n",
    "    y_list=[]\n",
    "    for i in range(len):\n",
    "        temp=[]\n",
    "        for j in range(max_val):\n",
    "            if(x[i]==j):\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "            #print(temp)\n",
    "        y_list.append(temp)\n",
    "    return y_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.55945675 -0.55945675  2.06254185 ...  2.0522595  -0.55945675\n",
      "  -0.55945675]\n",
      " [-0.5380259  -0.5380259  -0.5380259  ... -0.5380259  -0.5380259\n",
      "  -0.5380259 ]\n",
      " [-0.6486501  -0.6486501  -0.6486501  ... -0.6486501  -0.6486501\n",
      "  -0.6486501 ]\n",
      " ...\n",
      " [-0.64973918 -0.64973918 -0.64973918 ... -0.64973918 -0.64973918\n",
      "  -0.64973918]\n",
      " [-0.59745866 -0.59745866 -0.59745866 ... -0.59745866 -0.59745866\n",
      "  -0.59745866]\n",
      " [-0.62629522 -0.62629522 -0.62629522 ... -0.62629522 -0.62629522\n",
      "  -0.62629522]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "xtrain=train[:,1:785]\n",
    "\n",
    "xmean = np.mean(xtrain , axis=1)\n",
    "means_expanded = np.outer(xmean, np.ones(784))\n",
    "#print(means_expanded)\n",
    "xtrain = xtrain - means_expanded\n",
    "\n",
    "xstd = np.std(xtrain , axis=1)\n",
    "std_expanded = np.outer(xstd, np.ones(784))\n",
    "#print(std_expanded)\n",
    "xtrain = xtrain*1.0/std_expanded \n",
    "\n",
    "true_label = train[:,785:]\n",
    "y_true=np.array(encode_into_prob(true_label,10))\n",
    "y_true=y_true.transpose()\n",
    "\n",
    "#print(type(y_true))\n",
    "#print(y_true.transpose())\n",
    "print(xtrain)\n",
    "print((y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(batch_train,hidden_layers):\n",
    "     \n",
    "    global weight_matrix_list\n",
    "    global bias_list\n",
    "    global preactivation_list \n",
    "    preactivation_list=[]\n",
    "    global activation_list\n",
    "    activation_list=[]\n",
    "    global y_hat\n",
    "    y_hat=[]\n",
    "    a_new=[]\n",
    "    a_last_layer=[]\n",
    "    nos_data = len(batch_train)\n",
    "    #print(nos_data)\n",
    "    h=batch_train.transpose()\n",
    "    preactivation_list.append(h)\n",
    "    activation_list.append(h)\n",
    "    #print(h)\n",
    "    \n",
    "#     print(\"y_hat in feed\\n\",y_hat )\n",
    "    \n",
    "    for j in range(hidden_layers):\n",
    "        \n",
    "#         print(\".............................\")\n",
    "#         print(\"activation for layer \", j)\n",
    "#         print(activation_list[j] , activation_list[j].shape)\n",
    "#         print(\"weight\",j+1)\n",
    "#         print(weight_matrix_list[j], weight_matrix_list[j].shape)\n",
    "#         print(\"bias \",j+1)\n",
    "#         print(bias_list[j],bias_list[j].shape)\n",
    "        \n",
    "        a_new = bias_list[j]+np.matmul(weight_matrix_list[j].transpose(),activation_list[j])\n",
    "        preactivation_list.append(a_new)\n",
    "        \n",
    "#         print(\"preactivation for layer\",j+1)\n",
    "#         print(preactivation_list[j+1], preactivation_list[j+1].shape)\n",
    "        \n",
    "        h = 1.0/(1.0+np.exp(-1*preactivation_list[j+1]))\n",
    "        activation_list.append(h)\n",
    "\n",
    "    \n",
    "    j=hidden_layers\n",
    "#     print(\".............................\")\n",
    "#     print(\"activation for layer \", j)\n",
    "#     print(activation_list[j] , activation_list[j].shape)\n",
    "#     print(\"weight\",j+1)\n",
    "#     print(weight_matrix_list[j], weight_matrix_list[j].shape)\n",
    "#     print(\"bias \",j+1)\n",
    "#     print(bias_list[j],bias_list[j].shape)\n",
    "    \n",
    "    a_last_layer = bias_list[j]+np.matmul(weight_matrix_list[j].transpose(),activation_list[j])\n",
    "    preactivation_list.append(a_last_layer)\n",
    "    \n",
    "#     print(\"last activation\")\n",
    "#     print(a_last_layer,a_last_layer.shape)\n",
    "\n",
    "    y_hat = np.array(output(a_last_layer,batch_train))\n",
    "    y_hat = y_hat.transpose()\n",
    "    \n",
    "#     print(\"y_hat in feedforward\")\n",
    "#     print(y_hat, y_hat.shape)\n",
    "    \n",
    "    \n",
    "def output(a_last_layer,batch_train):\n",
    "    y_hat_initial=[]\n",
    "    y_hat_local=[]\n",
    "    nos_data=len(batch_train)\n",
    "    for i in range(nos_data):\n",
    "        y_hat_initial.append(softmax(a_last_layer[:,i:i+1].transpose()))\n",
    "\n",
    "    length = len(y_hat_initial)\n",
    "    for i in range(length):\n",
    "        y_hat_local.append(y_hat_initial[i][0])\n",
    "    \n",
    "#     print(\"y_hat_local\", y_hat_local)\n",
    "#     print(\"y_hat_initial\",y_hat_initial)\n",
    "    return y_hat_local\n",
    "\n",
    "def softmax(row_vector):\n",
    "    sum_all=0\n",
    "    row_vector = np.exp(row_vector)\n",
    "    sum_all = np.sum(row_vector , axis=1)         #print(\"row_vector\", row_vector)\n",
    "    row_vector = (row_vector*1.0/sum_all)         #print(\"sum_all\",sum_all)\n",
    "    return row_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(y_true_batch):\n",
    "    \n",
    "#     print(\"weigt in backpropogation\", weight_matrix_list)\n",
    "#     print(\"...........y_true_batch..........\\n\",y_true_batch)\n",
    "    \n",
    "    global grad_a_k_list\n",
    "    grad_a_k_list=[]\n",
    "    \n",
    "    global grad_w_k_list\n",
    "    grad_w_k_list=[]\n",
    "    \n",
    "    global grad_h_k_list\n",
    "    grad_h_k_list=[]\n",
    "    \n",
    "    global grad_b_k_list\n",
    "    grad_b_k_list=[]\n",
    "    \n",
    "    global grad_b\n",
    "    grad_b=[]\n",
    "    \n",
    "    global grad_g_dash_a_k_list\n",
    "    grad_g_dash_a_k_list = []\n",
    "    \n",
    "    global grad_a_last\n",
    "    grad_a_last=[]\n",
    "    \n",
    "    k = num_hidden+1\n",
    "    \n",
    "#     print(\"--------------------------in Backpropagation---------------------\")\n",
    "    \n",
    "    grad_g_dash_a_k_list = g_dash(preactivation_list)\n",
    "    \n",
    "#     print(\"preactivation_list....................\")\n",
    "#     print(\"Nos. of matrices in preactivation_list is\", len(preactivation_list))\n",
    "#     print(preactivation_list)\n",
    "#     print(\"g_dash..................\")\n",
    "#     print(\"Nos. of matrices in g_dash is \", len(grad_g_dash_a_k_list))\n",
    "#     print(grad_g_dash_a_k_list)\n",
    "    \n",
    "    grad_a_last = -np.subtract(y_true_batch,y_hat)\n",
    "    \n",
    "#     print(\"y_true_batch \\n\", y_true_batch)\n",
    "#     print(\"y_hat \\n\",y_hat)\n",
    "    \n",
    "    grad_a_k_list.insert(0,grad_a_last)\n",
    "    \n",
    "#     print(\"grad_a_last_layer\", k)\n",
    "#     print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "        \n",
    "    while(k>0):\n",
    "        \n",
    "#         print(\".................grad_compute at layer\",k)\n",
    "        \n",
    "        grad_w_k_list.insert(0,np.matmul(grad_a_k_list[0],preactivation_list[k-1].transpose()))\n",
    "        \n",
    "#         print(\"grad_a\", k)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "#         print('preactivation  a_',k-1)\n",
    "#         print(preactivation_list[k-1],preactivation_list[k-1].shape)\n",
    "#         print(\"grad_w_\",k)\n",
    "#         print(grad_w_k_list[0],grad_w_k_list[0].shape)\n",
    "        \n",
    "        grad_b_k_list.insert(0,grad_a_k_list[0])\n",
    "        \n",
    "#         print(\"grad_b\",k)\n",
    "#         print(grad_b_k_list[0],grad_b_k_list[0].shape)\n",
    "        \n",
    "        grad_h_k_list.insert(0,np.matmul(grad_w_k_list[0].transpose(),grad_a_k_list[0]))\n",
    "        \n",
    "#         print(\"grad_w\",k)\n",
    "#         print(grad_w_k_list[0],grad_w_k_list[0].shape)\n",
    "#         print(\"grad_a\",k)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "#         print(\"grad_h\",k-1)\n",
    "#         print(grad_h_k_list[0],grad_h_k_list[0].shape)\n",
    "        \n",
    "        grad_a_k_list.insert(0,np.multiply(grad_h_k_list[0],grad_g_dash_a_k_list[k-1]))\n",
    "        \n",
    "#         print(\"grad_h_k_list[0]\",k-1)\n",
    "#         print(grad_h_k_list[0],grad_h_k_list[0].shape)\n",
    "#         print(\"grad_g_dash_a_k_list[k-1]\",k-1)\n",
    "#         print(grad_g_dash_a_k_list[k-1],grad_g_dash_a_k_list[k-1].shape)\n",
    "#         print(\"grad_a\",k-1)\n",
    "#         print(grad_a_k_list[0],grad_a_k_list[0].shape)\n",
    "        k=k-1\n",
    "#         print(\"grad_a_ik_list\",grad_a_k_list[0])\n",
    "    \n",
    "    sum_all_grad_b_of_data(grad_b_k_list)\n",
    "    \n",
    "\n",
    "def sum_all_grad_b_of_data(grad_b_k_list):\n",
    "    length=len(grad_b_k_list)\n",
    "    i=0\n",
    "    while(i<length):\n",
    "        row=[]\n",
    "        row = np.sum(grad_b_k_list[i],1)\n",
    "        j = len(row)\n",
    "        #print(row.shape)\n",
    "        row = row[:, np.newaxis]\n",
    "        #print(row.shape , row)\n",
    "        grad_b.append(row)\n",
    "        i+=1\n",
    "    #print(\"grad_b\",grad_b)\n",
    "\n",
    "def g_dash(preactivation_list):\n",
    "    length=len(preactivation_list)\n",
    "    a_modified = preactivation_list[0:length]\n",
    "    g_dash_a_k_list=[]\n",
    "    for i in range(length):\n",
    "        a=(1.0/(1+np.exp(-a_modified[i])))*(1-(1.0/(1+np.exp(-a_modified[i]))))\n",
    "        g_dash_a_k_list.append(a)\n",
    "    return g_dash_a_k_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_yhat_to_classes(y_hat_local):\n",
    "    col = len(y_hat_local[0])\n",
    "    max_val=0\n",
    "    for j in range(col):\n",
    "        max_val = y_hat_local[0][j]\n",
    "        index=0\n",
    "        for i in range(9):\n",
    "            if(y_hat_local[i+1][j] > max_val):\n",
    "                y_hat_local[index][j]=0\n",
    "                index = i+1\n",
    "                max_val=y_hat[i+1][j]\n",
    "            else :\n",
    "                y_hat_local[i+1][j]=0\n",
    "        y_hat_local[index][j]=1\n",
    "    return y_hat_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 10]\n",
      "2\n",
      "[array([[0.00842745, 0.00879241, 0.00240955, ..., 0.00867346, 0.00374577,\n",
      "        0.0099145 ],\n",
      "       [0.00154602, 0.00238633, 0.00399281, ..., 0.0076772 , 0.00281038,\n",
      "        0.00559487],\n",
      "       [0.00098803, 0.00973544, 0.00837488, ..., 0.00328418, 0.00619729,\n",
      "        0.00870626],\n",
      "       ...,\n",
      "       [0.00039782, 0.0069763 , 0.00365968, ..., 0.00213939, 0.00625135,\n",
      "        0.00761   ],\n",
      "       [0.00562398, 0.0003659 , 0.0041835 , ..., 0.00035561, 0.0092253 ,\n",
      "        0.00751426],\n",
      "       [0.00176516, 0.00712558, 0.00739367, ..., 0.00836057, 0.0035143 ,\n",
      "        0.00888762]])]\n",
      "[array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]])]\n"
     ]
    }
   ],
   "source": [
    "#ip_neurons = 3 #input layer\n",
    "ip_neurons = 784\n",
    "num_hidden = 0\n",
    "encoding_bits=10\n",
    "sizes = []\n",
    "sizes.insert(0,ip_neurons)\n",
    "sizes.append(encoding_bits)\n",
    "print(sizes)\n",
    "print(len(sizes))\n",
    "\n",
    "weight_matrix_list = []\n",
    "\n",
    "bias_list =[]\n",
    "y_hat= []\n",
    "\n",
    "for i in range(int(num_hidden)+1):\n",
    "    weight_matrix_list.append(0.01*np.random.rand(sizes[i],sizes[i+1]))\n",
    "    bias_list.append(0*np.random.rand(sizes[i+1],1))\n",
    "print(weight_matrix_list)\n",
    "#print(len(weight_matrix_list))\n",
    "\n",
    "print(bias_list)\n",
    "#print(hlist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_gd(weight_matrix_list,bias_list,xtrain,num_hidden,sizes):\n",
    "    \n",
    "    prev_v_w = [] \n",
    "    prev_v_b = []\n",
    "    for i in range(int(num_hidden)+1):\n",
    "        prev_v_w.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "        prev_v_b.append(0*np.random.rand(sizes[i+1],1))\n",
    "    \n",
    "    v_w = [] \n",
    "    v_b =[]\n",
    "    for i in range(int(num_hidden)+1):\n",
    "        v_w.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "        v_b.append(0*np.random.rand(sizes[i+1],1))\n",
    "        \n",
    "    len_w = len(weight_matrix_list)  \n",
    "    len_b = len(bias_list)\n",
    "    \n",
    "    eta = 0.001\n",
    "    batch_size = 10\n",
    "    num_points_seen = 0\n",
    "    gamma = 0.4\n",
    "    epochs = 35\n",
    "    t=0\n",
    "    data_length = len(xtrain)\n",
    "    no_of_batch = int(data_length/batch_size)\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        for batch in range(no_of_batch):\n",
    "            dw=[]\n",
    "            db=[]\n",
    "            for i in range(int(num_hidden)+1):\n",
    "                dw.append(0*np.random.rand(sizes[i],sizes[i+1]))\n",
    "                db.append(0*np.random.rand(sizes[i+1],1))\n",
    "            \n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                l = batch_size*batch + i\n",
    "                r = batch_size*batch + i + 1\n",
    "                feedforward(xtrain[l:r,:],num_hidden)\n",
    "                #print(l , r)\n",
    "                backpropagation(y_true[:,l:r])\n",
    "\n",
    "                for j in range(len_w): \n",
    "                    dw[j] += grad_w_k_list[j].transpose()\n",
    "                                    \n",
    "                for j in range(len_b):\n",
    "                    db[j] += grad_b[j]\n",
    "                                \n",
    "            \n",
    "            for j in range(len_w): \n",
    "                v_w[j] = gamma*prev_v_w[j] + eta*dw[j]\n",
    "                                    \n",
    "            for j in range(len_b):\n",
    "                v_b[j] = gamma*prev_v_b[j] + eta*db[j]\n",
    "                \n",
    "            for j in range(len_w):\n",
    "                weight_matrix_list[j] += -1*v_w[j]\n",
    "            \n",
    "            for j in range(len_b):\n",
    "                bias_list[j] = -1*v_b[j]\n",
    "                \n",
    "            for j in range(len_w): \n",
    "                prev_v_w[j] = v_w[j]\n",
    "                                    \n",
    "            for j in range(len_b):\n",
    "                prev_v_b[j] = v_b[j]\n",
    "                \n",
    "            \n",
    "        \n",
    "        print(\"end of epoch\" , t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of epoch 0\n",
      "end of epoch 1\n",
      "end of epoch 2\n",
      "end of epoch 3\n",
      "end of epoch 4\n",
      "end of epoch 5\n",
      "end of epoch 6\n",
      "end of epoch 7\n",
      "end of epoch 8\n",
      "end of epoch 9\n",
      "end of epoch 10\n",
      "end of epoch 11\n",
      "end of epoch 12\n",
      "end of epoch 13\n",
      "end of epoch 14\n",
      "end of epoch 15\n",
      "end of epoch 16\n",
      "end of epoch 17\n",
      "end of epoch 18\n",
      "end of epoch 19\n",
      "end of epoch 20\n",
      "end of epoch 21\n",
      "end of epoch 22\n",
      "end of epoch 23\n",
      "end of epoch 24\n",
      "end of epoch 25\n",
      "end of epoch 26\n",
      "end of epoch 27\n",
      "end of epoch 28\n",
      "end of epoch 29\n",
      "end of epoch 30\n",
      "end of epoch 31\n",
      "end of epoch 32\n",
      "end of epoch 33\n",
      "end of epoch 34\n"
     ]
    }
   ],
   "source": [
    "momentum_gd(weight_matrix_list,bias_list,xtrain,num_hidden,sizes)\n",
    "#print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.64986232e-16]\n",
      " [6.38675862e-05]\n",
      " [6.13861823e-09]\n",
      " [7.15616519e-10]\n",
      " [1.24159298e-20]\n",
      " [1.40912592e-17]\n",
      " [9.99906458e-01]\n",
      " [9.47444685e-06]\n",
      " [6.55901599e-06]\n",
      " [1.36342679e-05]]\n"
     ]
    }
   ],
   "source": [
    "feedforward(xtrain,num_hidden)\n",
    "print(y_hat)\n",
    "y_hat = decode_yhat_to_classes(y_hat)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation(y_hat):\n",
    "    y_predict=[]\n",
    "    col = len(y_hat[0])\n",
    "    for j in range(col):\n",
    "        for i in range(10):\n",
    "            if(y_hat[i][j]==1):\n",
    "                y_predict.append(i)\n",
    "                break\n",
    "    return np.array(y_predict)\n",
    "y_predict = classifcation(y_hat)\n",
    "print((y_predict))\n",
    "y_predict = y_predict[:, np.newaxis]\n",
    "print((y_predict))\n",
    "print(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LN Pandey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "def decode_yhat_to_classes(y_hat):\n",
    "    col = len(y_hat[0])\n",
    "    max_val=0\n",
    "    for j in range(col):\n",
    "        max_val = y_hat[0][j]\n",
    "        index=0\n",
    "        for i in range(9):\n",
    "            if(y_hat[i+1][j] > max_val):\n",
    "                y_hat[index][j]=0\n",
    "                index = i+1\n",
    "                max_val=y_hat[i+1][j]\n",
    "            else :\n",
    "                y_hat[i+1][j]=0\n",
    "        y_hat[index][j]=1\n",
    "    return y_hat\n",
    "\n",
    "xtest = pd.read_csv('test.csv').as_matrix()\n",
    "test=xtest[:,1:]\n",
    "\n",
    "xmean = np.mean(test , axis=1)\n",
    "means_expanded = np.outer(xmean, np.ones(784))\n",
    "#print(means_expanded)\n",
    "test = test - means_expanded\n",
    "\n",
    "xstd = np.std(test , axis=1)\n",
    "std_expanded = np.outer(xstd, np.ones(784))\n",
    "#print(std_expanded)\n",
    "test = test*1.0/std_expanded \n",
    "\n",
    "\n",
    "feedforward(test,num_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.05187311e-14 5.77366058e-06 4.29929625e-04 ... 4.37526007e-14\n",
      "  4.80713883e-14 4.49936893e-15]\n",
      " [6.22146047e-10 1.62808594e-08 8.98580287e-01 ... 1.03597862e-07\n",
      "  3.44185033e-14 9.99994791e-01]\n",
      " [2.67913388e-06 4.03262572e-02 2.83430854e-04 ... 2.57192647e-12\n",
      "  6.80261103e-11 2.25162677e-13]\n",
      " ...\n",
      " [3.42187952e-06 2.32486976e-01 2.65746822e-04 ... 7.44347296e-17\n",
      "  7.37954888e-01 1.90159711e-10]\n",
      " [4.10042890e-10 5.89087705e-01 4.64403979e-09 ... 2.24184607e-25\n",
      "  2.62045083e-01 3.01454119e-19]\n",
      " [2.11614101e-07 1.35654591e-13 9.92224358e-02 ... 9.99999891e-01\n",
      "  2.70496795e-15 8.73197715e-16]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat)\n",
    "y_hat = decode_yhat_to_classes(y_hat)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifcation(y_hat):\n",
    "    y_predict=[]\n",
    "    col = len(y_hat[0])\n",
    "    for j in range(col):\n",
    "        for i in range(10):\n",
    "            if(y_hat[i][j]==1):\n",
    "                y_predict.append(i)\n",
    "                break\n",
    "    return np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 1 ... 9 7 1]\n",
      "[[6]\n",
      " [8]\n",
      " [1]\n",
      " ...\n",
      " [9]\n",
      " [7]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifcation(y_hat)\n",
    "print((y_predict))\n",
    "y_predict = y_predict[:, np.newaxis]\n",
    "print((y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_to_y_predict(y_predict):\n",
    "    ide=[]\n",
    "    row=len(y_predict)\n",
    "    for i in range(row):\n",
    "        ide.append(i)\n",
    "    ide=np.array(ide)\n",
    "    ide=ide[:,np.newaxis]\n",
    "    y= np.hstack((ide,y_predict))\n",
    "    #print(y_predict, ide)\n",
    "    return y           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [8]\n",
      " [1]\n",
      " ...\n",
      " [9]\n",
      " [7]\n",
      " [1]]\n",
      "[[   0    6]\n",
      " [   1    8]\n",
      " [   2    1]\n",
      " ...\n",
      " [9997    9]\n",
      " [9998    7]\n",
      " [9999    1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)\n",
    "#y_predict= np.random.randint(10, size=(10000, 1))\n",
    "y_predict= add_id_to_y_predict(y_predict)\n",
    "print(y_predict)\n",
    "x,y = y_predict.shape\n",
    "#print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predict_from_momentum.csv', 'w', newline='') as f:\n",
    "    thewriter = csv.writer(f)\n",
    "    row,col=y_predict.shape \n",
    "    thewriter.writerow(['id','label'])\n",
    "    for i in range(row):\n",
    "        thewriter.writerow(y_predict[i])\n",
    "#out.close()\n",
    "#np.savetxt(\"foo.csv\", y_predict, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.74224471e-05 8.02264595e-04 1.51039757e-06 ... 5.62434990e-05\n",
      "  1.79285011e-12 6.22880350e-07]\n",
      " [7.62237033e-01 3.12140336e-04 9.98373561e-01 ... 1.98156894e-04\n",
      "  2.60701929e-08 5.30945066e-03]\n",
      " [2.56872572e-06 2.80413107e-03 1.04042595e-03 ... 2.37363219e-04\n",
      "  1.16089260e-07 1.55871007e-04]\n",
      " ...\n",
      " [5.04730495e-04 1.81416288e-01 9.88803573e-07 ... 2.04466145e-03\n",
      "  9.33437547e-15 2.22964139e-03]\n",
      " [1.74129178e-07 1.38734604e-03 1.48487543e-08 ... 1.44726347e-07\n",
      "  1.17193353e-16 1.26111623e-02]\n",
      " [5.71122666e-10 2.80570528e-01 2.11814141e-07 ... 2.33313477e-02\n",
      "  9.99997923e-01 1.98158737e-03]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def classifcation(y_hat):\n",
    "    y_predict=[]\n",
    "    col = len(y_hat[0])\n",
    "    for j in range(col):\n",
    "        for i in range(10):\n",
    "            if(y_hat[i][j]==1):\n",
    "                y_predict.append(i)\n",
    "                break\n",
    "    return np.array(y_predict)\n",
    "feedforward(xtrain,num_hidden)\n",
    "print(y_hat)\n",
    "y_hat = decode_yhat_to_classes(y_hat)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 9 1 ... 6 9 6]\n",
      "[[1]\n",
      " [9]\n",
      " [1]\n",
      " ...\n",
      " [6]\n",
      " [9]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifcation(y_hat)\n",
    "print((y_predict))\n",
    "y_predict = y_predict[:, np.newaxis]\n",
    "print((y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7615454545454545\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in range(55000):\n",
    "    if(y_predict[i]==true_label[i]):\n",
    "        cnt+=1\n",
    "acc = cnt/55000\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
